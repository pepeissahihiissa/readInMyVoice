# Style-Bert-VITS2 セットアップ〜学習 完全手順書

動作確認日：2026-02-21  
動作確認環境：Windows 11、NVIDIA GPU（VRAM 8GB以上推奨）

> ⚠️ パッケージの更新により、将来的にこの手順が動作しなくなる可能性があります。動作確認日を参考にしてください。

---

## 必要なもの

- Windows 11（Windows 10でも動作する可能性はありますが未確認）
- NVIDIA製GPU（VRAM 8GB以上推奨）
- NVIDIAドライバの最新版（事前にインストール済みであること）
- インターネット接続（インストール中に数GBのダウンロードが発生します）
- Python・Gitの事前インストールは不要です

---

## STEP 1：ファイルのダウンロードと配置

### 1-1. sbv2.zip をダウンロードして解凍する

以下のURLからzipファイルをダウンロードします。

```
https://github.com/litagin02/Style-Bert-VITS2/releases/latest/download/sbv2.zip
```

解凍先は **パスに日本語・スペースが含まれないフォルダ** を選んでください。

例：`C:\sbv2\`

### 1-2. 修正版バッチファイルを上書きコピーする

配布している `Install-Style-Bert-VITS2.bat`と`patch.ps1` を、解凍したフォルダ（`C:\sbv2\` など）に上書きコピーします。

> **なぜ修正版が必要なのか**  
> 公式のバッチファイルは作成後に各パッケージが独立してアップデートされたため、そのままでは動作しない問題が複数あります。修正版ではこれらをすべて自動で対処しています。

---

## STEP 2：インストールの実行

`Install-Style-Bert-VITS2.bat` をダブルクリックして実行します。

処理の流れ（すべて自動で行われます）：

1. Gitのダウンロード（Gitが未インストールの場合）
2. Style-Bert-VITS2のソースコードを取得
3. Python 3.10.11（埋め込み版）のダウンロード
4. 仮想環境の作成
5. PyTorch（CUDA 11.8版）のインストール
6. 依存パッケージ一式のインストール
7. 互換性パッチの適用（2箇所、自動で行われます）
8. モデルファイルのダウンロード（数GB、時間がかかります）
9. 初回起動・ブラウザでGUIが開く

**所要時間の目安：** ネット環境によりますが30〜60分程度です。

### インストール完了の確認

ブラウザに `http://localhost:7860` が自動で開き、GUIが表示されれば成功です。

---

## STEP 3：学習用データの録音

### 録音の方針

- **棒読みにならないようにする** ── 台本の読み上げより自然な会話のほうが品質が上がります
- 目標録音時間：**30〜45分**（最低20分）
- 静かな部屋で、マイクとの距離を一定に保つ
- ノイズキャンセル機能は **OFF** にする

### 録音前に準備しておくと良いもの

- **水やお茶** ── 長時間の録音で喉が渇きます。飲んだ直後はマイクから離れるか録音を一時停止してください（飲む音が入ります）
- **録音は複数ファイルに分けてOK** ── 疲れてきたら録音を止めて休憩し、再開したら新しいファイルとして録音するのがおすすめです。後の処理で複数ファイルをまとめて扱えます

### 録音中に気をつけること

- マイクを触る操作音、キーボード・マウスの操作音、飲食の音はなるべく避ける
- 多少入ってしまった場合も後の文字起こし結果確認で取り除けます

### ChatGPTを使った録音方法（おすすめ）

台本なしで自然な声を録るための方法です。

1. スマートフォンに ChatGPT アプリをインストールする
2. PCの録音ソフト（Windowsのサウンドレコーダー等）を起動する
3. イヤホンでChatGPTの返答を聞きながら、自分の声をPCマイクで録音する
4. 自然な会話のテンポで話す
5. 「こんにちは」「ありがとうございます」など、配信でよく使うフレーズを意識して含める

### 録音形式

- WAV形式で保存（MP3は避ける）
- サンプリングレートは 44100Hz または 24000Hz

---

## STEP 4：データの準備（スライス〜文字起こし）

録音したWAVファイルを、SBV2に学習させるための短いセグメントに自動分割します。

### 4-1. 録音ファイルを inputs フォルダに置く

以下のフォルダにWAVファイルをコピーします。複数ファイルでも問題ありません。

```
C:\sbv2\Style-Bert-VITS2\inputs\
```

### 4-2. データセット作成タブを選択する

GUIで「データセット作成」のタブを選択して移動します。

### 4-3. スライスを実行する

1. 「モデル名」欄に任意の名前を入力します（例：`myvoice`）
2. 「スライスを実行」をクリックします
3. デフォルト設定のままで問題ありません

スライス処理により、録音ファイルが2〜10秒程度の短いセグメントに自動分割されます。無音部分も自動的に除去されます。

### 4-4. 文字起こしを実行する

「音声の文字起こし」をクリックして、完了まで待ちます。CPUで処理するため、**30分の音声で1時間程度かかります**。その間はそのまま放置してかまいません。

文字起こし結果は以下のファイルに保存されます。

```
C:\sbv2\Style-Bert-VITS2\Data\myvoice\esd.list
```

> **文字起こし結果の確認と雑音対処**  
> `esd.list` をメモ帳などで開いて内容を確認しましょう。文字起こしが明らかにおかしい行（意味不明な文字列・空行など）はそのセグメントに雑音が含まれている可能性が高いので、その行ごと削除するのが有効です。誤認識が少し残る程度なら修正しなくても学習は進みますが、気になる箇所は直しておくと品質が上がります。

---

## STEP 5：学習の実行

### 5-1. 学習タブを選択する

GUIの学習タブを選択します。

### 5-2. 前処理を実行する

モデル名を入力し、「自動前処理を実行」をクリックして、完了まで待ちます。

### 5-3. 学習設定を確認して学習を開始する

| 設定項目 | 推奨値 |
|----------|--------|
| バッチサイズ | VRAM 6GB未満：1、8GB：4、12GB以上：8 |
| 学習ステップ数 | 300〜500エポックを目安に |

設定を確認したら「学習を開始する」をクリックします。

**学習時間の目安：** GPUスペックと録音量によって数時間かかります。

---

## STEP 6：生成モデルの確認と選択

学習が完了すると、以下のフォルダに複数のモデルファイル（`.safetensors`）が生成されます。

```
C:\sbv2\Style-Bert-VITS2\model_assets\myvoice\
```

### 6-1. 音声合成タブを選択する

GUIの音声合成タブを選択します。。

### 6-2. モデルを切り替えながら音声を生成して確認する

任意のテキストを入力し、モデルファイルを何種類か切り替えながら音声を生成します。最も自然に聞こえるものを選んでください。

---

## 2回目以降の起動方法

インストールは初回のみです。2回目以降は以下のバッチを使います。

| やること | 使うファイル |
|----------|-------------|
| 音声生成・モデル確認 | `App.bat` |
| データ追加・前処理 | `Dataset.bat` |
| 追加学習 | `Train.bat` |

---

## トラブルシューティング

**ブラウザが自動で開かない**  
→ ブラウザで `http://localhost:7860` に手動でアクセスしてください。

**GPUが認識されない**  
→ NVIDIAドライバのバージョンを確認してください。CUDA 11.8に対応したドライバが必要です。

**学習が途中で止まる**  
→ VRAMが不足している可能性があります。バッチサイズを下げてください。

**音声生成が遅い**  
→ GUIの設定でCPUではなくGPUが選択されているか確認してください。

**文字起こしでエラーが出る**  
→ インストールが正常に完了していれば、CPU処理で自動実行されます。エラーが続く場合はインストールをやり直してください。

---

## 環境情報（参考）

| 項目 | バージョン |
|------|-----------|
| Python | 3.10.11（埋め込み版、自動取得） |
| PyTorch | 2.7.1+cu118 |
| CUDA | 11.8 |
| transformers | 4.57.6 |
| faster-whisper | 1.2.1 |
| ctranslate2 | 4.4.0 |
| pyopenjtalk | pyopenjtalk-plus 0.4.1 |
| setuptools | 69.5.1（<70固定） |

---

## 注意事項

- パッケージの更新により、将来的にこの手順が動作しなくなる可能性があります。動作確認日を参考にしてください。
- 文字起こしはCPUで実行します。faster-whisperのGPU実行にはCUDA 12系のDLLが必要ですが、PyTorch cu118環境には含まれていないためです。
- `setuptools<70` の固定は将来的に問題になる可能性があります（`pkg_resources` 廃止の方向のため）。
- `pyopenjtalk-plus` は非公式パッケージです。公式の `pyopenjtalk` がWindows向けwheelを提供するようになれば切り替えを検討してください。
